# ğŸ§  Medical RAG Chatbot

> â€œInformation is not knowledge.â€  
> â€” *Albert Einstein*

---

## ğŸ“˜ Overview

**Medical RAG Chatbot** is a command-line assistant designed to answer evidence-based medical questions using scientific papers (e.g., PubMed). It leverages **Retrieval-Augmented Generation (RAG)** and integrates vector databases, LLMs (like GPT or Ollama), and user feedback for enhanced precision and trustworthiness.

All responses are grounded strictly in retrieved scientific content â€” ideal for clinicians, researchers, or medical students.

---

## ğŸ—‚ï¸ Project Structure

```
medical-rag-chatbot/
â”‚
â”œâ”€â”€ app/                            # ğŸ“¦ Main application module
â”‚   â”œâ”€â”€ cli/                        # ğŸ–¥ï¸ CLI entrypoint
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ cli.py
â”‚   â”œâ”€â”€ configs/                    # âš™ï¸ Paths, prompts, and key management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_api_key.py
â”‚   â”‚   â”œâ”€â”€ paths.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚   â”œâ”€â”€ core/                       # ğŸ” Core logic: RAG + vectorization
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag.py
â”‚   â”‚   â””â”€â”€ vectorization.py
â”‚   â”œâ”€â”€ models/                     # ğŸ¤– LLM and embedding model wrappers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chatting_model.py
â”‚   â”‚   â””â”€â”€ embedding_model.py
â”‚   â””â”€â”€ services/                   # ğŸ”§ Feedback, auto-update, and resets
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ auto_update.py
â”‚       â”œâ”€â”€ feedback.py
â”‚       â””â”€â”€ reset.py
â”‚
â”œâ”€â”€ data/                           # ğŸ“„ Folder to store PDF documents
â”œâ”€â”€ docs/                           # ğŸ“š Optional documentation
â”œâ”€â”€ tests/                          # âœ… Unit and integration tests
â”œâ”€â”€ .env.template                   # ğŸ” Template for environment variables
â”œâ”€â”€ .gitignore                      # ğŸš« Git exclusions
â”œâ”€â”€ main.py                         # ğŸš€ App entrypoint (runs the CLI)
â”œâ”€â”€ README.md                       # ğŸ“˜ Project documentation
â””â”€â”€ requirements.txt                # ğŸ“¦ Python dependencies
```

---

## ğŸš€ Features

- ğŸ” Vector-based semantic search over local PDF documents
- ğŸ§  LLM-powered answers with grounded scientific context
- ğŸ’¬ Feedback memory system to refine response behavior
- ğŸ“ Auto-indexing of newly added or updated PDFs
- ğŸ§ª Supports both OpenAI and local embedding/LLM engines
- ğŸ§¹ Flexible database reset via CLI flags

---

## ğŸ“¦ Installation

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

Optional (for markdown or unstructured content):

```bash
pip install "unstructured[md]"
```

---

### 2. Environment Setup

Copy the environment template and add your API keys:

```bash
cp .env.template .env
```

Edit `.env`:

```env
OPENAI_API_KEY=your-key-here
```

---

## ğŸ’¡ Usage

### Ask a question:

```bash
python3 main.py ask "What is the role of dopamine in Parkinson's?"
```

### Add user feedback:

```bash
python3 main.py feedback "Explain each finding more clearly and use numbered lists."
```

### Reset databases:

```bash
python3 main.py reset --all         # Full reset
python3 main.py reset --em          # Reset embedding DB
python3 main.py reset --fb          # Reset feedback DB
python3 main.py reset --fi          # Reset file index
```

---

## ğŸ§  Feedback System

- Feedback is stored in `feedback/feedback.json`.
- Every RAG prompt includes all historical feedback.
- Reinforces helpful patterns and filters unwanted ones over time.

---

## ğŸ§¾ Prompt Template

PROMPT_TEMPLATE = """

You are a professional AI assistant trained to answer complex scientific questions with a high degree of precision and clarity. Your task is to provide responses based **solely on the provided context**, which consists of excerpts from peer-reviewed scientific papers.

You are operating in the **medical and biomedical research domain**, where **accuracy, evidence-based reasoning, and cautious interpretation** are critical. You must **not guess, speculate, or hallucinate** any facts that are not explicitly present in the context.

If the context does **not contain enough information** to confidently address a part of the question, you must **clearly state that the information is insufficient**, or respond with **â€œI donâ€™t know based on the provided context.â€**

Do **not generate new knowledge** or provide personal opinions. Your role is strictly to **extract, summarize, and synthesize information that is directly supported by the context** you are given.

Incorporate the provided **user feedback** (if any) to improve tone, depth, or focus of your answer.

---

Context:
{context}

---

Feedback:
{feedback}

---

Question:
{question}
"""

---

## ğŸ“Œ Chunking Strategy

- Uses `RecursiveCharacterTextSplitter`
- Parameters:
  - `chunk_size = 1000`
  - `chunk_overlap = 150`
- Each chunk is assigned a unique ID: `source:page:index`

---

## ğŸ§  Future Enhancements

- ğŸ” Hybrid retrieval (BM25 + vector search)
- ğŸŒ Web interface from PubMed
- ğŸ“„ Summarization of multi-document answers
- âš—ï¸ Domain-specific model fine-tuning
- ğŸ§¬ Multi-modal inputs (e.g., images, figures)

---

## ğŸ” License

This project is open to everyone!
Feel free to use, edit, copy, paste, share, or even taste it â€” seriously, go wild! ğŸ½ï¸

Still, Always Be Civil (ABC)!

---

## ğŸ™ Acknowledgements

- Prof. Mark Turner at Case Western Reserve University
- Case Western Reserve University HPC
- Pixegami (https://github.com/pixegami)
- PubMed
- OpenAI
- Ollama
- LangChain
- ChromaDB